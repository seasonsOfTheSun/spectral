# -*- coding: utf-8 -*-
"""unpicking_an_autoencoder

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QTC-cLyeOrMayY_P3KR3Js_Te33ohIRc
"""

!pip install flax

# make test data
import numpy as np
n = 1000
x = 10*np.random.rand(n)
y = 10*np.random.rand(n)
z = np.sqrt(x**2 + y**2)+np.random.rand(n)
w = y**3/100 + z + np.random.rand(n)
u = z+w + np.random.rand(n)
v = z-w + np.random.rand(n)

X = np.vstack([z,w,u,v]).T

import matplotlib.pyplot as plt

plt.scatter(u,v,c='k',s=5.0)



# define stanndard autoencoder
import jax
import jax.numpy as jnp
import flax.linen as nn

class Encoder(nn.Module):
  output_dim : int

  def setup(self):
    self.layer1 = nn.Dense(self.output_dim)
  
  def __call__(self,X):
    return nn.relu(self.layer1(X))

class Decoder(nn.Module):
  output_dim : int
  def setup(self):
    self.layer2 = nn.Dense(self.output_dim)
  
  def __call__(self,X):
    return self.layer2(X)

class Autoencoder(nn.Module):

  def setup(self):
    self.encoder = Encoder()
    self.decoder = Decoder()

  def __call__(self,X):
    return self.decoder(self.encoder(X))


f = Autoencoder()

#store_parameters = parameters

@jax.jit
def mse(parameters, X):
  return np.mean((f.apply(parameters, X) - X)**2)





parameters['params']['decoder']['layer2']

store_parameters['params']['layer2']

import optax
import tqdm

parameters['params'].keys()

import flax
#parameters = flax.core.unfreeze(parameters)
#parameters['params']['encoder']['layer1'] = store_parameters['params']['layer1']
#parameters['params']['decoder']['layer2'] = store_parameters['params']['layer2']
#parameters = flax.core.freeze(parameters)









n = 1000
parameters = f.init(jax.random.PRNGKey(108),X)
optimizer = optax.adam(0.001)
state = optimizer.init(parameters)

out108 = []
for i in tqdm.tqdm(range(n)):
  value,grad = jax.value_and_grad(mse)(parameters, X)
  out108.append(value)
  updates,state = optimizer.update(grad, state,parameters)
  parameters = optax.apply_updates(parameters, updates)

parameters = f.init(jax.random.PRNGKey(107),X)
optimizer = optax.adam(0.001)
state = optimizer.init(parameters)


out107 = []
for i in tqdm.tqdm(range(n)):
  value,grad = jax.value_and_grad(mse)(parameters, X)
  out107.append(value)
  updates,state = optimizer.update(grad, state,parameters)
  parameters = optax.apply_updates(parameters, updates)

?plt.legend

h1 = plt.scatter(range(n), out107)
h2 = plt.scatter(range(n), out108)
plt.legend((h1, h2), ("seed=107", "seed=108"))
plt.suptitle("apparently initialization matters quite a bit...")

boop = f.bind(parameters)

xy_approximated = boop.encoder(X)
fig,axes = plt.subplots(ncols = 2, figsize = [7,3])
ax1,ax2 = axes.flatten()
ax1.scatter(xy_approximated[:,0],xy_approximated[:,1],c=x)
ax2.scatter(xy_approximated[:,0],xy_approximated[:,1],c=y)

xy_approximated = boop.encoder.layer1(X)
fig,axes = plt.subplots(ncols = 2, figsize = [7,3])
ax1,ax2 = axes.flatten()
ax1.scatter(xy_approximated[:,0],xy_approximated[:,1],c=x)
ax2.scatter(xy_approximated[:,0],xy_approximated[:,1],c=y)

xy_approximated = boop.encoder(X)
fig,axes = plt.subplots(ncols = 3, figsize = [10,3])
ax1,ax2,ax3 = axes.flatten()
ax1.scatter(xy_approximated[:,0],xy_approximated[:,1],c=z)
ax2.scatter(xy_approximated[:,0],xy_approximated[:,1],c=u)
ax3.scatter(xy_approximated[:,0],xy_approximated[:,1],c=v)

plt.scatter(xy_approximated[:,0],x)
plt.plot([0,10],[0,10])

plt.scatter(xy_approximated[:,1],y)
plt.plot([0,10],[0,10])



"""# Let's get spectral ðŸ‘»"""

!pip install umap-learn

import umap
import networkx as nx
import numpy as np
import scipy.sparse

nneighbors = 10
metric = 'euclidean'
rndstate = np.random.RandomState(108)
nodes = nodelist
adjacency,_,_ = umap.umap_.fuzzy_simplicial_set(X, nneighbors, rndstate, metric)

degrees = adjacency * np.ones(X.shape[0])
degrees_inv_sqrt = [1/np.sqrt(x) for x in degrees]
normalized_adjacency = (scipy.sparse.diags(degrees_inv_sqrt)*
                        adjacency*
                        scipy.sparse.diags(degrees_inv_sqrt))

n_evectors = 50                                                                                                          
e,evecs = scipy.sparse.linalg.eigsh(normalized_adjacency, k = n_evectors)

plt.scatter(y,evecs[:,-5])
#plt.plot([0,10],[0,10])









# define spectrally augmented autoencoder
import jax
import jax.numpy as jnp
import flax.linen as nn


class Encoder(nn.Module):
  output_dim : int

  def setup(self):
    self.layer1 = nn.Dense(self.output_dim)
  
  def __call__(self,X):
    return nn.relu(self.layer1(X))

class Decoder(nn.Module):
  output_dim : int
  def setup(self):
    self.layer2 = nn.Dense(self.output_dim)
  
  def __call__(self,X):
    return self.layer2(X)

class SpectralAutoencoder(nn.Module):
  io_dim : int
  n_latents : int
  n_evecs : int
  
  def setup(self):
    self.latent_encoder = Encoder(self.n_latents)
    self.spectral_encoder = Encoder(self.n_evecs)
    self.decoder = Decoder(self.io_dim)


  def __call__(self,X,evecs):
    latent = self.latent_encoder(X)
    spectral_approximant = self.spectral_encoder(X)
    data_approximant = self.decoder(jnp.hstack([latent,spectral_approximant]))
    return spectral_approximant, data_approximant

io_dim = X.shape[1]
n_evecs = 30
f = SpectralAutoencoder(io_dim,2,n_evecs)
parameters = f.init(jax.random.PRNGKey(108), X, evecs[:,-n_evecs-1:-1])

@jax.jit
def mse(parameters, X, selected_evecs):
  evec_weight = jnp.ones(n_evecs)
  spectral_approximant, data_approximant = f.apply(parameters, X, selected_evecs)
  spectral_encoding_mse = jnp.mean(evec_weight*(spectral_approximant - selected_evecs)**2)
  data_encoding_mse = jnp.mean((data_approximant - X)**2)
  return spectral_encoding_mse + data_encoding_mse

selected_evecs = evecs[:,-n_evecs-1:-1]
jax.grad(mse)(parameters, X, selected_evecs);

parameters = f.init(jax.random.PRNGKey(108),X,selected_evecs)
optimizer = optax.adam(0.01)
state = optimizer.init(parameters)

out = []
for i in tqdm.tqdm(range(n)):
  value,grad = jax.value_and_grad(mse)(parameters, X, selected_evecs)
  out.append(value)
  updates,state = optimizer.update(grad, state,parameters)
  parameters = optax.apply_updates(parameters,updates)

plt.plot(out[400:])
plt.plot(out107[400:])



jax.jacfwd(jnp.hstack)([jnp.array([895049548.0, 839458.0, 6.66]),jnp.array([1.0, 1.0, 1.0])])







e

evecs



b = Encoder(1)
b.init(jax.random.PRNGKey(108), X)